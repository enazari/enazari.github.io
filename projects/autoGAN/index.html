<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta name="google-site-verification" content="c1_ireMrS6VGlox8sVODWIT69eOUaBySUjgbyIJf7jI"> 
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>AutoGAN | Ehsan  Nazari</title>
    <meta name="author" content="Ehsan  Nazari">
    <meta name="description" content="An Automated Human-out-of-the-Loop Approach for Training Generative Adversarial Networks">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://enazari.github.io/projects/autoGAN/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Ehsan </span>Nazari</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">AutoGAN</h1>
            <p class="post-description">An Automated Human-out-of-the-Loop Approach for Training Generative Adversarial Networks</p>
          </header>

          <article>
            <h3>Problem Definition</h3>

<p>Training a GAN can be quite complex compared to standard learning algorithms. Unlike optimizing an objective function, GAN training involves a competitive game where one player (the generator) tries to maximize an objective function while the other player (the discriminator) aims to minimize it. This presents a challenge in finding the Nash equilibrium, which is the potential solution to this game. <strong> Determining when to stop training a GAN is also a significant challenge</strong>, as there is no universally accepted criterion. Researchers often rely on visual inspection or quantitative evaluation metrics like Inception Score (IS) and Fréchet Inception Distance (FID). However, these approaches have limitations, such as the subjective nature of visual inspection and the need for pre-trained models for quantitative evaluation. <strong>This project aims to address these challenges and provide an automatic and systematic approach for determining the optimal point to stop GAN training across different data types.</strong></p>

<h3>The Solution</h3>

<p>We introduce an algorithm called AutoGAN, which aims to automate the training of GANs without the need for human intervention. Traditional GAN training can be challenging, requiring human involvement and subjective visual inspection. Moreover, most evaluation metrics are designed for image datasets, limiting the application of GANs to non-image data. AutoGAN addresses these issues by utilizing an oracle, a customizable scoring mechanism that assesses the quality of generated samples.</p>

<p>An oracle is a function that assesses a given generator and assigns a score that reflects the quality of the generated samples. The definition of a “better” sample depends on the specific oracle instance chosen by the end-user. For instance, in some cases, a “better” sample might closely match the dataset’s distribution. However, in other scenarios, it could indicate increased diversity in the data or, in the case of images, higher quality and sharpness.</p>

<p>The algorithm iteratively trains the GAN and evaluates its performance based on an oracle’s scores. AutoGAN allows for temporary performance dips, giving the GAN the opportunity to recover and reach optimal results. Once no further improvement is observed for a specified number of iterations, AutoGAN returns the best-trained GAN model. This algorithm minimizes human intervention and is applicable to various data types, including tabular and image data. Extensive experiments demonstrate the superiority of AutoGAN over GANs trained with manual visual inspection.</p>

<h3>An Oracle Instance</h3>
<p>FID oracle instance utilizes a truncated version of the InceptionNet model. Initially, the InceptionNet model is trained on the ImageNet dataset. Then, a GAN is trained on the target real dataset, and the generator component of the GAN generates a specific number of fake samples. Both the real and fake data are processed by the truncated InceptionNet model to obtain their respective InceptionNet-represented features. These features are used to calculate the Fréchet Inception Distance (FID) score. A lower FID score indicates higher quality outputs from the GAN.</p>
<div class="row">
    <div class="container" style="max-width: 100%;">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/autogan/fid.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="An oracle instance based on FID score" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
        </div>

</div>
<div class="caption">
    An oracle instance based on FID score
</div>

<h3>A Glimpse into Results</h3>
<p>In the figure bellow, a set of the comparative results of using a Conditional GAN trained via different methods, used for Oversampling of an imbalanced binarized dataset based on fashion-MNIST classes 2 and 4 is shown:</p>
<div class="row">
    <div class="container" style="max-width: 100%;">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/autogan/results.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Oversampling results of an imbalanced binarized dataset based on fashion-MNIST classes 2 and 4" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
        </div>

</div>
<div class="caption">
    The objective is to classify between class 2 and class 4 within an imbalanced fashion-MNIST dataset. The 'initial' data point signifies the outcomes obtained from classifying the imbalanced dataset, while the 'Manual' data point indicates the results obtained by classifying a balanced dataset. The balanced dataset was generated using a GAN, and the training process was manually monitored to determine the appropriate stopping point.
</div>

<p>In the figure above, all the points, except for the ones labeled as ‘initial’ and ‘Manual,’ represent different runs of AutoGAN using various Oracle instances. We can observe that both the ‘Manual’ method and the AutoGAN method show similar improvements in the minority class after oversampling. This suggests that we have achieved comparable results to a GAN that is manually inspected, using an automated system that operates without human intervention.</p>

<h3>The Potentials of the Solution</h3>
<p>Exploring the transferability of image-to-image translation techniques to tabular-to-tabular translation or applying image denoising methods to tabular data denoising could be interesting avenues for future research.</p>

<h3>The Published Results</h3>
<p>To gain a comprehensive understanding of the AutoGAN algorithm and access the extensive results from a wide range of experiments, I kindly refer you to our research paper:</p>
<div class="container">
<div class="publications">

  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 preview">
<figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/mfid.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="mfid.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>
</div>

        <!-- Entry bib key -->
        <div id="math11040977" class="col-sm-8">
        <!-- Title -->
        <div class="title">AutoGAN: An Automated Human-Out-of-the-Loop Approach for Training Generative Adversarial Networks</div>
        <!-- Author -->
        <div class="author">
        

        <em>Ehsan Nazari</em>, Paula Branco, and Guy-Vincent Jourdan</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Mathematics</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://www.mdpi.com/2227-7390/11/4/977" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Hyper Link</a>
<!-- -->
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-doi="10.3390/math11040977"></span>
<!--
              <span class="__dimensions_badge_embed__"
              
                data-doi="10.3390/math11040977"
              
              data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> -->
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Generative Adversarial Networks (GANs) have been used for many applications with overwhelming success. The training process of these models is complex, involving a zero-sum game between two neural networks trained in an adversarial manner. Thus, to use GANs, researchers and developers need to answer the question: “Is the GAN sufficiently trained?”. However, understanding when a GAN is well trained for a given problem is a challenging and laborious task that usually requires monitoring the training process and human intervention for assessing the quality of the GAN generated outcomes. Currently, there is no automatic mechanism for determining the required number of epochs that correspond to a well-trained GAN, allowing the training process to be safely stopped. In this paper, we propose AutoGAN, an algorithm that allows one to answer this question in a fully automatic manner with minimal human intervention, being applicable to different data modalities including imagery and tabular data. Through an extensive set of experiments, we show the clear advantage of our solution when compared against alternative methods, for a task where the GAN outputs are used as an oversampling method. Moreover, we show that AutoGAN not only determines a good stopping point for training the GAN, but it also allows one to run fewer training epochs to achieve a similar or better performance with the GAN outputs.</p>
          </div>
        </div>
      </div>
</li></ol>

</div>
</div>

<div class="container">
 The code for AutoGAN can be found at <a href="https://github.com/enazari/autoGAN" rel="external nofollow noopener" target="_blank">https://github.com/enazari/autoGAN</a>.
</div>


          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Ehsan  Nazari. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
